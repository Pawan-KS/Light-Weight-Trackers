{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# ckpt_og = torch.load('/workspace/tracking_datasets/STARKST_ep0050.pth.tar')\n",
    "# ckpt_sparse = torch.load('/workspace/tracking_datasets/stark/try/checkpoints/train/stark_sparse/baseline_got10k_only_sparse/STARKST_ep0001.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# ckpt_og = torch.load('/workspace/tracking_datasets/stark/exp_wacv_fin1/checkpoints/train/stark_st1/baseline_got10k_only_exp3/STARKST_ep0300.pth.tar')\n",
    "# ckpt_sparse = torch.load('/workspace/tracking_datasets/stark/exp_wacv_sparse_fin1/checkpoints/train/stark_sparse/baseline_got10k_only_sparse_fin_exp1/STARKST_ep0001.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_sparse['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ckpt_sparse['net'].keys():\n",
    "    if 'transformer' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# new_state = OrderedDict()\n",
    "\n",
    "# for key, value in ckpt_og['net'].items():\n",
    "#     if 'transformer' in key and 'in_proj_weight' in key:\n",
    "#         new_key = key[:-14] + 'qkv.weight'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'in_proj_bias' in key:\n",
    "#         new_key = key[:-12] + 'qkv.bias'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'out_proj.weight' in key:\n",
    "#         new_key = key[:-15] + 'proj.weight'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'out_proj.bias' in key:\n",
    "#         new_key = key[:-13] + 'proj.bias'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'linear1.weight' in key:\n",
    "#         new_key = key[:-14] + 'mlp.fc1.weight'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'linear1.bias' in key:\n",
    "#         new_key = key[:-12] + 'mlp.fc1.bias'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'linear2.weight' in key:\n",
    "#         new_key = key[:-14] + 'mlp.fc2.weight'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     elif 'transformer' in key and 'linear2.bias' in key:\n",
    "#         new_key = key[:-12] + 'mlp.fc2.bias'\n",
    "#         print(new_key)\n",
    "#         new_state[new_key] = value\n",
    "#     else:\n",
    "#         new_state[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_state = OrderedDict()\n",
    "\n",
    "for key, value in ckpt_og['net'].items():\n",
    "    if 'transformer' in key and 'in_proj_weight' in key:\n",
    "        new_key = key[:-14] + 'q.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[:value.shape[0]//3,:]\n",
    "        \n",
    "        new_key = key[:-14] + 'k.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[value.shape[0]//3:(value.shape[0]//3)*2,:]\n",
    "        \n",
    "        new_key = key[:-14] + 'v.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[(value.shape[0]//3)*2:,:]\n",
    "        \n",
    "    elif 'transformer' in key and 'in_proj_bias' in key:\n",
    "        new_key = key[:-12] + 'q.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[:value.shape[0]//3]\n",
    "        \n",
    "        new_key = key[:-12] + 'k.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[value.shape[0]//3:(value.shape[0]//3)*2]\n",
    "        \n",
    "        new_key = key[:-12] + 'v.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value[(value.shape[0]//3)*2:]\n",
    "        \n",
    "        \n",
    "    elif 'transformer' in key and 'out_proj.weight' in key:\n",
    "        new_key = key[:-15] + 'proj.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    elif 'transformer' in key and 'out_proj.bias' in key:\n",
    "        new_key = key[:-13] + 'proj.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    elif 'transformer' in key and 'linear1.weight' in key:\n",
    "        new_key = key[:-14] + 'mlp.fc1.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    elif 'transformer' in key and 'linear1.bias' in key:\n",
    "        new_key = key[:-12] + 'mlp.fc1.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    elif 'transformer' in key and 'linear2.weight' in key:\n",
    "        new_key = key[:-14] + 'mlp.fc2.weight'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    elif 'transformer' in key and 'linear2.bias' in key:\n",
    "        new_key = key[:-12] + 'mlp.fc2.bias'\n",
    "        print(new_key)\n",
    "        new_state[new_key] = value\n",
    "    else:\n",
    "        new_state[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models.stark import build_starks, build_starkst,build_starkst_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "config_module = importlib.import_module(\"lib.config.%s.config\" % 'stark_sparse')\n",
    "cfg = config_module.cfg\n",
    "config_module.update_config_from_file('/workspace/Stark/experiments/stark_sparse/baseline_got10k_only_sparse.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_starkst,build_starkst_sparse(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].load_state_dict(new_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_og['net'] = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ckpt_og,'/workspace/tracking_datasets/stark_sparse_pretrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_sparse['net']['transformer.encoder.layers.0.mlp.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_og['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STARKST_ep0001.pth.tar',\n",
       " 'STARKST_ep0002.pth.tar',\n",
       " 'STARKST_ep0003.pth.tar',\n",
       " 'STARKST_ep0004.pth.tar',\n",
       " 'STARKST_ep0005.pth.tar',\n",
       " 'STARKST_ep0006.pth.tar',\n",
       " 'STARKST_ep0007.pth.tar',\n",
       " 'STARKST_ep0008.pth.tar',\n",
       " 'STARKST_ep0009.pth.tar',\n",
       " 'STARKST_ep0010.pth.tar',\n",
       " 'STARKST_ep0011.pth.tar',\n",
       " 'STARKST_ep0012.pth.tar',\n",
       " 'STARKST_ep0013.pth.tar',\n",
       " 'STARKST_ep0014.pth.tar',\n",
       " 'STARKST_ep0015.pth.tar',\n",
       " 'STARKST_ep0016.pth.tar',\n",
       " 'STARKST_ep0017.pth.tar',\n",
       " 'STARKST_ep0018.pth.tar',\n",
       " 'STARKST_ep0019.pth.tar',\n",
       " 'STARKST_ep0020.pth.tar',\n",
       " 'STARKST_ep0021.pth.tar',\n",
       " 'STARKST_ep0022.pth.tar',\n",
       " 'STARKST_ep0023.pth.tar',\n",
       " 'STARKST_ep0024.pth.tar',\n",
       " 'STARKST_ep0025.pth.tar',\n",
       " 'STARKST_ep0026.pth.tar',\n",
       " 'STARKST_ep0027.pth.tar',\n",
       " 'STARKST_ep0028.pth.tar',\n",
       " 'STARKST_ep0029.pth.tar',\n",
       " 'STARKST_ep0030.pth.tar',\n",
       " 'STARKST_ep0031.pth.tar',\n",
       " 'STARKST_ep0032.pth.tar',\n",
       " 'STARKST_ep0033.pth.tar',\n",
       " 'STARKST_ep0034.pth.tar',\n",
       " 'STARKST_ep0035.pth.tar',\n",
       " 'STARKST_ep0036.pth.tar',\n",
       " 'STARKST_ep0037.pth.tar',\n",
       " 'STARKST_ep0038.pth.tar',\n",
       " 'STARKST_ep0039.pth.tar']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.listdir('/workspace/tracking_datasets/stark/exp1/checkpoints/train/stark_sparse/baseline_got10k_only_sparse')\n",
    "os.listdir('/workspace/tracking_datasets/stark/wacv_fin_sparse_exp1_no_clf/checkpoints/train/stark_sparse_no_clf/baseline_got10k_only_sparse_exp1_no_clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/wacv_fin_sparse_exp1_no_clf/checkpoints/train/stark_sparse_no_clf/baseline_got10k_only_sparse_exp1_no_clf/STARKST_ep0036.pth.tar')['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.7316, 0.7187, 0.6349, 0.8135, 0.6168, 0.7530, 0.7715, 0.4966,\n",
       "            0.6718, 0.8776, 0.8781, 0.7803, 0.8777, 0.7903, 0.6737, 0.8623,\n",
       "            0.5964, 0.7416, 0.6402, 0.5035, 0.7689, 0.8600, 0.7663, 0.7621]],\n",
       "\n",
       "          [[0.7840, 0.7995, 0.7902, 0.7244, 0.8296, 0.7946, 0.7882, 0.6624,\n",
       "            0.7081, 0.8227, 0.7984, 0.7114, 0.7969, 0.7471, 0.6994, 0.7390,\n",
       "            0.7131, 0.8210, 0.8344, 0.8119, 0.6735, 0.7719, 0.6825, 0.6749]],\n",
       "\n",
       "          [[0.8263, 0.9082, 0.7683, 0.8626, 0.8627, 0.8725, 0.9077, 0.7937,\n",
       "            0.7495, 0.8830, 0.8011, 0.8584, 0.8034, 0.7235, 0.7038, 0.7609,\n",
       "            0.7581, 0.8555, 0.7811, 0.7385, 0.6563, 0.8386, 0.9208, 0.7567]],\n",
       "\n",
       "          [[0.7855, 0.7555, 0.8277, 0.8406, 0.7164, 0.8835, 0.8334, 0.7500,\n",
       "            0.8157, 0.8089, 0.7788, 0.8052, 0.6710, 0.7520, 0.7277, 0.7737,\n",
       "            0.8056, 0.7729, 0.7844, 0.8502, 0.8194, 0.7436, 0.8414, 0.8393]]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['transformer.encoder.layers.0.self_attn.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/exp1/checkpoints/train/stark_sparse/baseline_got10k_only_sparse/STARKST_ep0008.pth.tar')['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'transformer.decoder.layers.4.self_attn.zeta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4976156ab96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformer.decoder.layers.4.self_attn.zeta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'transformer.decoder.layers.4.self_attn.zeta'"
     ]
    }
   ],
   "source": [
    "ckpt['transformer.decoder.layers.4.self_attn.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/exp1/checkpoints/train/stark_sparse/baseline_got10k_only_sparse/STARKST_ep00010.pth.tar')['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['transformer.encoder.layers.0.self_attn.zeta'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd '/workspace/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/workspace/tracking_datasets/stark/exp1_no_clf/checkpoints/train/stark_sparse_no_clf/baseline_got10k_only_sparse_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head channel: 256\n"
     ]
    }
   ],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=5\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import importlib\n",
    "from Stark_sparse.lib.models.stark import build_starks, build_starkst,build_starkst_sparse\n",
    "config_module = importlib.import_module(\"Stark_sparse.lib.config.%s.config\" % 'stark_sparse_no_clf')\n",
    "cfg = config_module.cfg\n",
    "config_module.update_config_from_file('/workspace/Stark_sparse/experiments/stark_sparse_no_clf/baseline_got10k_only_sparse_exp4.yaml')\n",
    "\n",
    "model = build_starkst_sparse(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mSTARKST_ep0001.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0020.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0039.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0002.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0021.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0040.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0003.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0022.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0041.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0004.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0023.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0042.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0005.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0024.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0043.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0006.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0025.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0044.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0007.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0026.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0045.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0008.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0027.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0046.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0009.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0028.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0047.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0010.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0029.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0048.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0011.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0030.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0049.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0012.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0031.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0050.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0013.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0032.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0051.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0014.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0033.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0052.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0015.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0034.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0053.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0016.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0035.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0054.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0017.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0036.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0055.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0018.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0037.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0056.pth.tar\u001b[0m\n",
      "\u001b[01;31mSTARKST_ep0019.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0038.pth.tar\u001b[0m  \u001b[01;31mSTARKST_ep0057.pth.tar\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls '/workspace/tracking_datasets/stark/exp4_sparse_no_clf/checkpoints/train/stark_sparse_no_clf/baseline_got10k_only_sparse_exp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/exp4_sparse_no_clf/checkpoints/train/stark_sparse_no_clf/baseline_got10k_only_sparse_exp4/STARKST_ep0050.pth.tar',map_location='cuda')['net']\n",
    "model.load_state_dict(ckpt, strict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = torch.load('/workspace/tracking_datasets/stark_sparse_pretrained.pth', map_location='cpu')['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(ckpt, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_attn, thresh_mlp, thresh_patch = model.transformer.compress_layerwise(0.5,0.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11754293739795685,\n",
       " 0.35394585132598877,\n",
       " 0.5073657631874084,\n",
       " 0.27834901213645935,\n",
       " 2.14479132409906e-05,\n",
       " 7.621758868481265e-06,\n",
       " 0.23036548495292664,\n",
       " 0.23030482232570648,\n",
       " 0.23070299625396729,\n",
       " 0.2304164469242096,\n",
       " 0.23113802075386047,\n",
       " 0.23077276349067688,\n",
       " 0.23278838396072388,\n",
       " 0.2319745421409607,\n",
       " 0.2488117814064026,\n",
       " 0.2762312591075897,\n",
       " 0.7809024453163147,\n",
       " 0.9797723889350891]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.encoder.layers[0].state_dict()['self_attn.zeta'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.encoder.layers[0].state_dict()['mlp.zeta'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "for i in range(6):\n",
    "    s1+=model.transformer.encoder.layers[i].self_attn.searched_zeta.sum().numpy()\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1336/1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.decoder.layers[0].state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.decoder.layers[0].state_dict()['multihead_attn.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.decoder.layers[0].state_dict()['mlp.zeta'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.encoder.layers[0].state_dict()['self_attn.q.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.decoder.layers[0].state_dict()['self_attn.q.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.transformer.encoder.layers[0].state_dict()['self_attn.zeta'].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.transformer.decoder.layers[0].state_dict()['multihead_attn.zeta'].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.transformer.decoder.layers[0].state_dict()['self_attn.zeta'].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.transformer.decoder.layers[0].state_dict()['mlp.zeta'].flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
