{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /workspace/tracking_dtat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/checkpoints/train/stark_st2/baseline_got10k_only/STARKST_ep0050.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/checkpoints/train/stark_sparse/baseline_got10k_only/STARKST_ep0030.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net']['backbone.0.body.layer1.0.conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net']['backbone.0.body.layer2.0.bn2.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net']['backbone.0.body.layer1.0.bn3.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 = torch.load('/workspace/tracking_datasets/STARKST_ep0050.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1['net']['backbone.0.body.layer2.0.bn2.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt['net'] ckpt1['net']\n",
    "for i in ckpt['net'].keys():\n",
    "#     print(i)\n",
    "    try:\n",
    "        if 'bn' in i:\n",
    "           print((ckpt['net'][i] - ckpt1['net'][i]).sum(),'      ',i)\n",
    "    except:\n",
    "        print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt['net'] ckpt1['net']\n",
    "for i in ckpt['net'].keys():\n",
    "#     print(i)\n",
    "    try:\n",
    "        if 'bn' in i:\n",
    "           print((ckpt['net'][i] - ckpt1['net'][i]).sum(),'      ',i)\n",
    "    except:\n",
    "        print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 = torch.load('/workspace/tracking_datasets/STARKST_ep0050.pth.tar')\n",
    "ckpt1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1['net']['transformer.encoder.layers.0.self_attn.in_proj_bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multihead_attn = nn.MultiheadAttention(512,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multihead_attn.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn.state_dict()['in_proj_bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.tensor as Tensor\n",
    "# def _in_projection_packed(q,k,v,w,b):\n",
    "#     r\"\"\"\n",
    "#     Performs the in-projection step of the attention operation, using packed weights.\n",
    "#     Output is a triple containing projection tensors for query, key and value.\n",
    "#     Args:\n",
    "#         q, k, v: query, key and value tensors to be projected. For self-attention,\n",
    "#             these are typically the same tensor; for encoder-decoder attention,\n",
    "#             k and v are typically the same tensor. (We take advantage of these\n",
    "#             identities for performance if they are present.) Regardless, q, k and v\n",
    "#             must share a common embedding dimension; otherwise their shapes may vary.\n",
    "#         w: projection weights for q, k and v, packed into a single tensor. Weights\n",
    "#             are packed along dimension 0, in q, k, v order.\n",
    "#         b: optional projection biases for q, k and v, packed into a single tensor\n",
    "#             in q, k, v order.\n",
    "#     Shape:\n",
    "#         Inputs:\n",
    "#         - q: :math:`(..., E)` where E is the embedding dimension\n",
    "#         - k: :math:`(..., E)` where E is the embedding dimension\n",
    "#         - v: :math:`(..., E)` where E is the embedding dimension\n",
    "#         - w: :math:`(E * 3, E)` where E is the embedding dimension\n",
    "#         - b: :math:`E * 3` where E is the embedding dimension\n",
    "#         Output:\n",
    "#         - in output list :math:`[q', k', v']`, each output tensor will have the\n",
    "#             same shape as the corresponding input tensor.\n",
    "#     \"\"\"\n",
    "#     E = q.size(-1)\n",
    "#     if k is v:\n",
    "#         if q is k:\n",
    "#             # self-attention\n",
    "#             return linear(q, w, b).chunk(3, dim=-1)\n",
    "#         else:\n",
    "#             # encoder-decoder attention\n",
    "#             w_q, w_kv = w.split([E, E * 2])\n",
    "#             if b is None:\n",
    "#                 b_q = b_kv = None\n",
    "#             else:\n",
    "#                 b_q, b_kv = b.split([E, E * 2])\n",
    "#             return (linear(q, w_q, b_q),) + linear(k, w_kv, b_kv).chunk(2, dim=-1)\n",
    "#     else:\n",
    "#         w_q, w_k, w_v = w.chunk(3)\n",
    "#         if b is None:\n",
    "#             b_q = b_k = b_v = None\n",
    "#         else:\n",
    "#             b_q, b_k, b_v = b.chunk(3)\n",
    "#         return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., num_patches=197):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = num_patches\n",
    "        head_dim = dim // num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q,k,v):\n",
    "        B, N, C = q.shape\n",
    "        \n",
    "        q = F.linear(q,self.qkv.weight.data[:self.dim,:],self.qkv.bias.data[:self.dim]).reshape(B, N, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        k = F.linear(k,self.qkv.weight.data[self.dim:self.dim*2,:],self.qkv.bias.data[self.dim:self.dim*2]).reshape(B, N, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        v = F.linear(v,self.qkv.weight.data[self.dim*2:self.dim*3,:],self.qkv.bias.data[self.dim*2:self.dim*3]).reshape(B, N, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        \n",
    "        q = q[0]\n",
    "        k = k[0]\n",
    "        v = v[0]\n",
    "#         qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "#         q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "#         print(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t = Attention(256,8,qkv_bias=True)\n",
    "# a_t.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t.state_dict()['qkv.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((2,1,8))\n",
    "y = torch.ones((2,1,8))*2\n",
    "z = torch.ones((2,1,8))*3\n",
    "\n",
    "# x = torch.rand((2,1,8))\n",
    "# y = x*2\n",
    "# z = x*3\n",
    "em = torch.cat((x,y,z),dim=1)\n",
    "print(em.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = Attention(8,8,qkv_bias=True)\n",
    "a_t(em,em,em).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t(em,em,em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = nn.MultiheadAttention(8,8)\n",
    "multihead_attn(em,em,em)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn(em,em,em)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ma = multihead_attn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_aa = a_t.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ckpt_ma.keys())):\n",
    "    ckpt_aa[list(ckpt_aa.keys())[i]] = ckpt_ma[list(ckpt_ma.keys())[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn.load_state_dict(ckpt_ma)\n",
    "a_t.load_state_dict(ckpt_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn.eval()\n",
    "a_t.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn(x.permute(1,0,2),y.permute(1,0,2),z.permute(1,0,2))[0].permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multihead_attn(em,em,em)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = torch.load('/workspace/STMTrack/models/googlenet/inception_v3_google-1a9a5a14-961cad7697695cca7d9ca4814b17a88d.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., num_patches=197):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = num_patches\n",
    "        head_dim = dim // num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q,k,v,attn_mask=None):\n",
    "        \n",
    "        q = q.permute(1,0,2)\n",
    "        k = k.permute(1,0,2)\n",
    "        v = v.permute(1,0,2)\n",
    "        \n",
    "        \n",
    "        B,N_q,N_k,N_v,C = q.shape[0],q.shape[1],k.shape[1],v.shape[1],q.shape[2]\n",
    "        \n",
    "        \n",
    "        q = F.linear(q,self.qkv.weight.data[:self.dim,:],self.qkv.bias.data[:self.dim]).reshape(B, N_q, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "        k = F.linear(k,self.qkv.weight.data[self.dim:self.dim*2,:],self.qkv.bias.data[self.dim:self.dim*2]).reshape(B, N_k, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "        v = F.linear(v,self.qkv.weight.data[self.dim*2:self.dim*3,:],self.qkv.bias.data[self.dim*2:self.dim*3]).reshape(B, N_v, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "\n",
    "        \n",
    "        print(q.shape,k.shape,v.shape)\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.to(torch.bool)\n",
    "\n",
    "            attn_mask = attn_mask.view(B, 1, 1, N_k).expand(-1, self.num_heads, -1, -1).reshape(B*self.num_heads, 1, N_k)\n",
    "\n",
    "            new_attn_mask = torch.zeros_like(attn_mask, dtype=q.dtype)\n",
    "            new_attn_mask.masked_fill_(attn_mask, float(\"-inf\"))\n",
    "            attn_mask = new_attn_mask\n",
    "        \n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn = torch.baddbmm(attn_mask, q.reshape(B*self.num_heads,N_q,C // self.num_heads), k.reshape(B*self.num_heads,N_k,C // self.num_heads).transpose(-2, -1)) * self.scale\n",
    "            attn = attn.reshape(B,self.num_heads,N_q,N_k)\n",
    "            \n",
    "        else:\n",
    "            attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "            \n",
    "        attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N_q, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., num_patches=197):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_patches = num_patches\n",
    "        head_dim = dim // num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.v = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.k = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        \n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q,k,v,attn_mask=None):\n",
    "        \n",
    "        q = q.permute(1,0,2)\n",
    "        k = k.permute(1,0,2)\n",
    "        v = v.permute(1,0,2)\n",
    "        \n",
    "        \n",
    "        B,N_q,N_k,N_v,C = q.shape[0],q.shape[1],k.shape[1],v.shape[1],q.shape[2]\n",
    "        \n",
    "        \n",
    "        q = self.q(q).reshape(B, N_q, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "        k = self.k(k).reshape(B, N_k, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "        v = self.v(v).reshape(B, N_v, 1, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)[0]\n",
    "\n",
    "        \n",
    "        print(q.shape,k.shape,v.shape)\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.to(torch.bool)\n",
    "\n",
    "            attn_mask = attn_mask.view(B, 1, 1, N_k).expand(-1, self.num_heads, -1, -1).reshape(B*self.num_heads, 1, N_k)\n",
    "\n",
    "            new_attn_mask = torch.zeros_like(attn_mask, dtype=q.dtype)\n",
    "            new_attn_mask.masked_fill_(attn_mask, float(\"-inf\"))\n",
    "            attn_mask = new_attn_mask\n",
    "        \n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn = torch.baddbmm(attn_mask, q.reshape(B*self.num_heads,N_q,C // self.num_heads), k.reshape(B*self.num_heads,N_k,C // self.num_heads).transpose(-2, -1)) * self.scale\n",
    "            attn = attn.reshape(B,self.num_heads,N_q,N_k)\n",
    "            \n",
    "        else:\n",
    "            attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "            \n",
    "        attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N_q, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus = MultiHeadAttention(16,8,qkv_bias=True)\n",
    "att = nn.MultiheadAttention(16,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['q.weight', 'q.bias', 'v.weight', 'v.bias', 'k.weight', 'k.bias', 'proj.weight', 'proj.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['in_proj_weight', 'in_proj_bias', 'out_proj.weight', 'out_proj.bias'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_ckpt = cus.state_dict()\n",
    "att_ckpt = att.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_ckpt['q.weight'] = att_ckpt['in_proj_weight'][:16,:]\n",
    "cus_ckpt['k.weight'] = att_ckpt['in_proj_weight'][16:32,:]\n",
    "cus_ckpt['v.weight'] = att_ckpt['in_proj_weight'][32:48,:]\n",
    "\n",
    "cus_ckpt['q.bias'] = att_ckpt['in_proj_bias'][:16]\n",
    "cus_ckpt['k.bias'] = att_ckpt['in_proj_bias'][16:32]\n",
    "cus_ckpt['v.bias'] = att_ckpt['in_proj_bias'][32:48]\n",
    "\n",
    "cus_ckpt['proj.weight'] = att_ckpt['out_proj.weight']\n",
    "cus_ckpt['proj.bias'] = att_ckpt['out_proj.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cus_ckpt.keys())):\n",
    "    cus_ckpt[list(cus_ckpt.keys())[i]] = att_ckpt[list(att_ckpt.keys())[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus.load_state_dict(cus_ckpt)\n",
    "att.load_state_dict(att_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand((4,2,16))\n",
    "k = torch.rand((8,2,16))\n",
    "v = torch.rand((8,2,16))\n",
    "\n",
    "att_mask = torch.randint(0, 2, (2,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 2]) torch.Size([2, 8, 8, 2]) torch.Size([2, 8, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3039e-01,  1.3611e-01, -3.8231e-02, -1.8606e-01,  7.8508e-02,\n",
       "          -1.5547e-01, -1.0202e-01,  1.4707e-01, -2.2271e-01, -6.0652e-02,\n",
       "           5.9124e-03, -1.1733e-01,  2.2855e-01, -7.1308e-02, -9.2387e-03,\n",
       "          -6.3134e-02],\n",
       "         [-1.3239e-01,  1.8836e-01, -5.6286e-02, -1.6565e-01,  1.3476e-01,\n",
       "          -7.2032e-02, -1.4834e-01,  9.6906e-02, -2.3595e-01,  1.2915e-02,\n",
       "           6.3564e-04, -5.1516e-02,  1.9877e-01, -9.3561e-02, -3.8331e-03,\n",
       "           6.8967e-04]],\n",
       "\n",
       "        [[-2.3067e-01,  1.3946e-01, -3.8197e-02, -1.8524e-01,  8.0181e-02,\n",
       "          -1.5689e-01, -1.0177e-01,  1.5134e-01, -2.2213e-01, -5.9793e-02,\n",
       "           2.6337e-03, -1.2083e-01,  2.2955e-01, -7.1954e-02, -1.2970e-02,\n",
       "          -6.4759e-02],\n",
       "         [-1.3532e-01,  1.8466e-01, -5.6312e-02, -1.6681e-01,  1.3347e-01,\n",
       "          -7.1122e-02, -1.4797e-01,  9.5620e-02, -2.3218e-01,  1.0999e-02,\n",
       "           1.3105e-03, -4.8062e-02,  2.0119e-01, -9.2952e-02,  5.3359e-04,\n",
       "           3.1482e-03]],\n",
       "\n",
       "        [[-2.2973e-01,  1.4134e-01, -3.9172e-02, -1.8557e-01,  8.0414e-02,\n",
       "          -1.5539e-01, -1.0291e-01,  1.5249e-01, -2.2218e-01, -5.9603e-02,\n",
       "           1.8612e-03, -1.2102e-01,  2.3141e-01, -7.3610e-02, -1.1549e-02,\n",
       "          -6.4955e-02],\n",
       "         [-1.3619e-01,  1.8737e-01, -5.6562e-02, -1.6325e-01,  1.3288e-01,\n",
       "          -7.3274e-02, -1.4786e-01,  9.4329e-02, -2.3279e-01,  1.2672e-02,\n",
       "           4.2749e-03, -5.1787e-02,  2.0184e-01, -9.4496e-02, -7.3082e-05,\n",
       "           4.0494e-03]],\n",
       "\n",
       "        [[-2.3105e-01,  1.3690e-01, -3.6860e-02, -1.8360e-01,  7.5828e-02,\n",
       "          -1.5248e-01, -1.0271e-01,  1.4616e-01, -2.2179e-01, -5.7505e-02,\n",
       "           4.3922e-03, -1.1970e-01,  2.2838e-01, -7.4148e-02, -8.7011e-03,\n",
       "          -6.2961e-02],\n",
       "         [-1.2957e-01,  1.8708e-01, -5.8252e-02, -1.6696e-01,  1.3774e-01,\n",
       "          -7.3033e-02, -1.4667e-01,  9.9321e-02, -2.3575e-01,  1.0998e-02,\n",
       "           8.5516e-04, -5.2497e-02,  1.9777e-01, -9.3514e-02, -8.4452e-03,\n",
       "          -5.4522e-04]]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cus(q,k,v,None)  #bs,nhead,seq_len,head_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 2]) torch.Size([2, 8, 8, 2]) torch.Size([2, 8, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2296,  0.1092, -0.0378, -0.1628,  0.0602, -0.1009, -0.0860,\n",
       "           0.1388, -0.1583, -0.0290,  0.0086, -0.1117,  0.2411, -0.1210,\n",
       "           0.0429, -0.0440],\n",
       "         [-0.1784,  0.1857, -0.0227, -0.1172,  0.1376, -0.1487, -0.1750,\n",
       "           0.0757, -0.2508,  0.0054,  0.0099, -0.0773,  0.1493, -0.0864,\n",
       "          -0.0455,  0.0017]],\n",
       "\n",
       "        [[-0.2307,  0.1094, -0.0371, -0.1627,  0.0602, -0.1042, -0.0857,\n",
       "           0.1411, -0.1589, -0.0278,  0.0055, -0.1146,  0.2418, -0.1201,\n",
       "           0.0384, -0.0451],\n",
       "         [-0.1803,  0.1793, -0.0297, -0.1227,  0.1416, -0.1496, -0.1742,\n",
       "           0.0762, -0.2485, -0.0013,  0.0114, -0.0698,  0.1559, -0.0885,\n",
       "          -0.0457,  0.0036]],\n",
       "\n",
       "        [[-0.2302,  0.1119, -0.0372, -0.1625,  0.0608, -0.1014, -0.0871,\n",
       "           0.1430, -0.1583, -0.0277,  0.0057, -0.1148,  0.2433, -0.1220,\n",
       "           0.0407, -0.0465],\n",
       "         [-0.1820,  0.1818, -0.0264, -0.1165,  0.1388, -0.1527, -0.1756,\n",
       "           0.0687, -0.2475,  0.0007,  0.0159, -0.0733,  0.1508, -0.0866,\n",
       "          -0.0461,  0.0044]],\n",
       "\n",
       "        [[-0.2288,  0.1122, -0.0356, -0.1615,  0.0591, -0.0971, -0.0860,\n",
       "           0.1393, -0.1581, -0.0269,  0.0088, -0.1142,  0.2399, -0.1221,\n",
       "           0.0417, -0.0454],\n",
       "         [-0.1744,  0.1892, -0.0220, -0.1165,  0.1404, -0.1468, -0.1727,\n",
       "           0.0778, -0.2512,  0.0056,  0.0123, -0.0797,  0.1485, -0.0862,\n",
       "          -0.0504, -0.0032]]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cus(q,k,v,att_mask)  #bs,nhead,seq_len,head_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3039e-01,  1.3611e-01, -3.8231e-02, -1.8606e-01,  7.8508e-02,\n",
       "          -1.5547e-01, -1.0202e-01,  1.4707e-01, -2.2271e-01, -6.0652e-02,\n",
       "           5.9123e-03, -1.1733e-01,  2.2855e-01, -7.1308e-02, -9.2388e-03,\n",
       "          -6.3134e-02],\n",
       "         [-1.3239e-01,  1.8836e-01, -5.6286e-02, -1.6565e-01,  1.3476e-01,\n",
       "          -7.2032e-02, -1.4834e-01,  9.6906e-02, -2.3595e-01,  1.2915e-02,\n",
       "           6.3564e-04, -5.1516e-02,  1.9877e-01, -9.3561e-02, -3.8331e-03,\n",
       "           6.8967e-04]],\n",
       "\n",
       "        [[-2.3067e-01,  1.3946e-01, -3.8197e-02, -1.8524e-01,  8.0181e-02,\n",
       "          -1.5689e-01, -1.0177e-01,  1.5134e-01, -2.2213e-01, -5.9793e-02,\n",
       "           2.6337e-03, -1.2083e-01,  2.2955e-01, -7.1954e-02, -1.2970e-02,\n",
       "          -6.4759e-02],\n",
       "         [-1.3532e-01,  1.8466e-01, -5.6312e-02, -1.6681e-01,  1.3347e-01,\n",
       "          -7.1122e-02, -1.4797e-01,  9.5620e-02, -2.3218e-01,  1.0999e-02,\n",
       "           1.3105e-03, -4.8062e-02,  2.0119e-01, -9.2952e-02,  5.3361e-04,\n",
       "           3.1482e-03]],\n",
       "\n",
       "        [[-2.2973e-01,  1.4134e-01, -3.9172e-02, -1.8557e-01,  8.0414e-02,\n",
       "          -1.5539e-01, -1.0291e-01,  1.5249e-01, -2.2218e-01, -5.9603e-02,\n",
       "           1.8612e-03, -1.2102e-01,  2.3141e-01, -7.3610e-02, -1.1549e-02,\n",
       "          -6.4955e-02],\n",
       "         [-1.3619e-01,  1.8737e-01, -5.6562e-02, -1.6325e-01,  1.3288e-01,\n",
       "          -7.3274e-02, -1.4786e-01,  9.4329e-02, -2.3279e-01,  1.2672e-02,\n",
       "           4.2749e-03, -5.1787e-02,  2.0184e-01, -9.4496e-02, -7.3082e-05,\n",
       "           4.0494e-03]],\n",
       "\n",
       "        [[-2.3105e-01,  1.3690e-01, -3.6860e-02, -1.8360e-01,  7.5828e-02,\n",
       "          -1.5248e-01, -1.0271e-01,  1.4616e-01, -2.2179e-01, -5.7505e-02,\n",
       "           4.3922e-03, -1.1970e-01,  2.2838e-01, -7.4148e-02, -8.7011e-03,\n",
       "          -6.2961e-02],\n",
       "         [-1.2957e-01,  1.8708e-01, -5.8252e-02, -1.6696e-01,  1.3774e-01,\n",
       "          -7.3033e-02, -1.4667e-01,  9.9321e-02, -2.3575e-01,  1.0998e-02,\n",
       "           8.5516e-04, -5.2497e-02,  1.9777e-01, -9.3514e-02, -8.4452e-03,\n",
       "          -5.4524e-04]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(q,k,v,key_padding_mask = None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2296,  0.1092, -0.0378, -0.1628,  0.0602, -0.1009, -0.0860,\n",
       "           0.1388, -0.1583, -0.0290,  0.0086, -0.1117,  0.2411, -0.1210,\n",
       "           0.0429, -0.0440],\n",
       "         [-0.1784,  0.1857, -0.0227, -0.1172,  0.1376, -0.1487, -0.1750,\n",
       "           0.0757, -0.2508,  0.0054,  0.0099, -0.0773,  0.1493, -0.0864,\n",
       "          -0.0455,  0.0017]],\n",
       "\n",
       "        [[-0.2307,  0.1094, -0.0371, -0.1627,  0.0602, -0.1042, -0.0857,\n",
       "           0.1411, -0.1589, -0.0278,  0.0055, -0.1146,  0.2418, -0.1201,\n",
       "           0.0384, -0.0451],\n",
       "         [-0.1803,  0.1793, -0.0297, -0.1227,  0.1416, -0.1496, -0.1742,\n",
       "           0.0762, -0.2485, -0.0013,  0.0114, -0.0698,  0.1559, -0.0885,\n",
       "          -0.0457,  0.0036]],\n",
       "\n",
       "        [[-0.2302,  0.1119, -0.0372, -0.1625,  0.0608, -0.1014, -0.0871,\n",
       "           0.1430, -0.1583, -0.0277,  0.0057, -0.1148,  0.2433, -0.1220,\n",
       "           0.0407, -0.0465],\n",
       "         [-0.1820,  0.1818, -0.0264, -0.1165,  0.1388, -0.1527, -0.1756,\n",
       "           0.0687, -0.2475,  0.0007,  0.0159, -0.0733,  0.1508, -0.0866,\n",
       "          -0.0461,  0.0044]],\n",
       "\n",
       "        [[-0.2288,  0.1122, -0.0356, -0.1615,  0.0591, -0.0971, -0.0860,\n",
       "           0.1393, -0.1581, -0.0269,  0.0088, -0.1142,  0.2399, -0.1221,\n",
       "           0.0417, -0.0454],\n",
       "         [-0.1744,  0.1892, -0.0220, -0.1165,  0.1404, -0.1468, -0.1727,\n",
       "           0.0778, -0.2512,  0.0056,  0.0123, -0.0797,  0.1485, -0.0862,\n",
       "          -0.0504, -0.0032]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(q,k,v,key_padding_mask = att_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torc\n",
    "ckpt = torch.load('/workspace/tracking_datasets/stark/try/checkpoints/train/stark_sparse/baseline_got10k_only_sparse/STARKST_ep0001.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net']['transformer.encoder.layers.0.mlp.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['net']['transformer.encoder.layers.0.self_attn.zeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt1 = torch.load('/workspace/tracking_datasets/stark/try/checkpoints/train/stark_sparse/baseline_got10k_only_sparse/STARKST_ep0001.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1['net']['transformer.encoder.layers.0.self_attn.qkv.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt2 = torch.load('/workspace/tracking_datasets/STARKST_ep0050.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt2['net']['transformer.encoder.layers.0.self_attn.in_proj_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
